import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
import matplotlib.pyplot as plt

# Step 1: Load the dataset (Iris dataset for example)
data = load_iris()
X = data.data  # Features
y = data.target  # Target labels

# Step 2: Calculate the mean of the whole dataset
mean_total = np.mean(X, axis=0)

# Step 3: Calculate the class-wise mean vectors
class_labels = np.unique(y)
mean_class = np.array([np.mean(X[y == label], axis=0) for label in class_labels])

# Step 4: Calculate the Between-Class Scatter Matrix (SB)
SB = np.zeros((X.shape[1], X.shape[1]))

for label, mean_c in zip(class_labels, mean_class):
    n = X[y == label].shape[0]  # Number of samples in class
    mean_diff = (mean_c - mean_total).reshape(-1, 1)  # (mean_c - mean_total) as column vector
    SB += n * (mean_diff).dot(mean_diff.T)

# Step 5: Calculate the Within-Class Scatter Matrix (SW)
SW = np.zeros((X.shape[1], X.shape[1]))

for label in class_labels:
    class_data = X[y == label]
    mean_c = mean_class[label]  # Class mean
    # Subtract the class mean from each sample and compute the covariance
    SW += (class_data - mean_c).T.dot(class_data - mean_c)

# Step 6: Compute the eigenvalues and eigenvectors of the matrix SW^(-1) * SB
# Solve the eigenvalue problem for the matrix SW^(-1) * SB
eigvals, eigvecs = np.linalg.eig(np.linalg.inv(SW).dot(SB))

# Step 7: Sort the eigenvalues in decreasing order and select the top k eigenvectors
# Pair eigenvalues with their corresponding eigenvectors
eig_pairs = [(np.abs(eigvals[i]), eigvecs[:, i]) for i in range(len(eigvals))]

# Sort the eigenpairs in decreasing order of eigenvalues
eig_pairs.sort(key=lambda x: x[0], reverse=True)

# Step 8: Create a matrix W containing the eigenvectors corresponding to the largest eigenvalues
k = 2  # For 2D projection (can vary depending on the required dimensionality)
W = np.hstack([eig_pairs[i][1].reshape(-1, 1) for i in range(k)])

# Step 9: Project the original data onto the new k-dimensional space
X_lda = X.dot(W)

# Visualize the result
plt.figure(figsize=(8, 6))
plt.scatter(X_lda[y == 0], np.zeros_like(X_lda[y == 0]), label="Class 0", color='red')
plt.scatter(X_lda[y == 1], np.zeros_like(X_lda[y == 1]), label="Class 1", color='blue')
plt.scatter(X_lda[y == 2], np.zeros_like(X_lda[y == 2]), label="Class 2", color='green')
plt.xlabel("First Discriminant Axis")
plt.title("LDA of Iris Dataset (2D Projection)")
plt.legend(loc="best")
plt.show()

# Display eigenvalues and eigenvectors
print("\nEigenvalues (in decreasing order):")
for eigval, eigvec in eig_pairs[:k]:
    print(f"Eigenvalue: {eigval}, Eigenvector: {eigvec}")
